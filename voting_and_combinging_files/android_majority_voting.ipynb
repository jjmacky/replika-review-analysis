{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 =  pd.read_csv('gpt_processed_reviews/android/run_1_replika_reviews.csv', keep_default_na=False)\n",
    "df2 =  pd.read_csv('gpt_processed_reviews/android/run_1_replika_reviews.csv', keep_default_na=False)\n",
    "df3 =  pd.read_csv('gpt_processed_reviews/android/run_1_replika_reviews.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure the three seperate files have the same columns. There were a few corner cases causing a need for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['User Name', 'Review Date', 'Star Rating',\n",
    "       'Review Text', 'Response Date', 'Response Text', 'echoed_user_name',\n",
    "       'coherence_and_clarity_of_review', 'gender_of_user', 'gender_of_ai',\n",
    "       'name_user_gave_ai', 'age_of_user', 'duration_of_app_usage',\n",
    "       'frequency_of_app_usage', 'relationship_status_of_user',\n",
    "       'empathy_of_ai', 'behavior_of_ai', 'inappropriate_frequency',\n",
    "       'inappropriate_nature', 'ai_support_level', 'support_types',\n",
    "       'user_mental_state_before_ai', 'effect_of_ai_on_user_mental_state',\n",
    "       'stress_before_ai', 'effect_of_ai_on_stress', 'loneliness_before_ai',\n",
    "       'effect_of_ai_on_loneliness', 'depression_or_anxiety_before_ai',\n",
    "       'effect_of_ai_on_depression_or_anxiety', 'suicidal_thoughts_presence',\n",
    "       'effect_of_ai_on_suicidal_thoughts', 'other_despair_types',\n",
    "       'effect_of_ai_on_other_despair', 'user_dependence',\n",
    "       'real_life_relationship_impact', 'limitations_of_ai',\n",
    "       'technical_issues', 'privacy_concerns', 'feature_restriction_impact',\n",
    "       'cost_impact_on_accessibility', 'impact_of_ai_updates',\n",
    "       'user_satisfaction_with_policy_decisions',\n",
    "       'overall_mental_health_impact_of_company_decisions']\n",
    "\n",
    "df1 = df1[columns]\n",
    "df2 = df2[columns]\n",
    "df3 = df3[columns]\n",
    "\n",
    "df1['short_review_text'] = df1['Review Text'].apply(lambda text: ' '.join(text.split()[:10]))\n",
    "df1['key'] = df1['User Name'] + df1['Review Date'] + df1['short_review_text']\n",
    "\n",
    "df2['short_review_text'] = df2['Review Text'].apply(lambda text: ' '.join(text.split()[:10]))\n",
    "df2['key'] = df2['User Name'] + df2['Review Date'] + df2['short_review_text']\n",
    "\n",
    "df3['short_review_text'] = df3['Review Text'].apply(lambda text: ' '.join(text.split()[:10]))\n",
    "df3['key'] = df3['User Name'] + df3['Review Date'] + df3['short_review_text']\n",
    "\n",
    "\n",
    "common_keys = set(df1['key']).intersection(df2['key']).intersection(df3['key'])\n",
    "df1 = df1[df1['key'].isin(common_keys)].drop_duplicates(subset='key')\n",
    "df2 = df2[df2['key'].isin(common_keys)].drop_duplicates(subset='key')\n",
    "df3 = df3[df3['key'].isin(common_keys)].drop_duplicates(subset='key')\n",
    "\n",
    "df1.drop(['short_review_text'], axis=1, inplace=True)\n",
    "df2.drop(['short_review_text'], axis=1, inplace=True)\n",
    "df3.drop(['short_review_text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import random\n",
    "\n",
    "\n",
    "# Columns to apply majority voting on\n",
    "vote_columns = ['support_types', 'other_despair_types', 'limitations_of_ai']\n",
    "single_value_columns = [col for col in df1.columns if col not in vote_columns and col != 'key']\n",
    "\n",
    "# Prepare a new DataFrame to store the results\n",
    "all_keys = df1['key'].unique()\n",
    "final_df = pd.DataFrame(all_keys, columns=['key'])\n",
    "final_df.set_index('key', inplace=True)\n",
    "\n",
    "for key in all_keys:\n",
    "    user_data = []\n",
    "    for df in [df1, df2, df3]:\n",
    "        data = df[df['key'] == key]\n",
    "        if not data.empty:\n",
    "            user_data.append(data.iloc[0])\n",
    "\n",
    "    # Implementing majority voting for single value columns\n",
    "    for col in single_value_columns:\n",
    "        # Filter out 'None' and 'nan' explicitly treated as a string\n",
    "        values = [ud[col] for ud in user_data if pd.notnull(ud[col]) and ud[col] not in [None, 'nan', '']]\n",
    "        if values:\n",
    "            # Count the most common value that is neither None nor 'nan'\n",
    "            most_common_value = Counter(values).most_common(1)[0][0]\n",
    "            final_df.at[key, col] = most_common_value\n",
    "        else:\n",
    "            # If no valid values, check for any available non-None and non-'nan' values\n",
    "            available_values = [ud[col] for ud in user_data if pd.notnull(ud[col]) and ud[col] not in [None, 'nan', '']]\n",
    "            if available_values:\n",
    "                final_df.at[key, col] = random.choice(available_values)\n",
    "            else:\n",
    "                # Assign pd.NA if no valid values are available\n",
    "                final_df.at[key, col] = pd.NA\n",
    "\n",
    "    # Majority voting for multi-value columns\n",
    "    for col in vote_columns:\n",
    "        # Filter out None and 'nan' explicitly treated as strings\n",
    "        all_values = list(chain(*[str(ud[col]).split(', ') for ud in user_data if ud[col] not in [None, 'nan', '']]))\n",
    "        if all_values:\n",
    "            value_counts = Counter(all_values)\n",
    "            selected_values = [value for value, count in value_counts.items() if count > 1]\n",
    "            final_df.at[key, col] = ', '.join(selected_values)\n",
    "\n",
    "# Ensuring no duplicates of 'key' exist before resetting the index\n",
    "if 'key' in final_df.columns:\n",
    "    final_df.drop(columns=['key'], inplace=True)\n",
    "\n",
    "# Reset the index to move 'key' from index to a column\n",
    "final_df.reset_index(inplace=True)\n",
    "\n",
    "# Ensure all 'nan' strings and None values are treated uniformly as missing values\n",
    "final_df.replace({'nan': pd.NA, None: pd.NA}, inplace=True)\n",
    "\n",
    "# Save the DataFrame\n",
    "final_df.to_csv('combined_reviews_final.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
